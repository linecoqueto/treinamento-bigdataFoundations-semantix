##---------------------------------------------------------------
##Realizar com uso do MySQL
##---------------------------------------------------------------

aline@aline-virtualbox:~/treinamentos/docker-bigdata$ docker exec -it database bash
root@database:/# mysql -psecret

##---------------------------------------------------------------
#1. Criar a tabela cp_titles_date, contendo a cópia da tabela titles com os campos title e to_date
##---------------------------------------------------------------

mysql> create table cp_titles_date as select title, to_date from titles;
Query OK, 443308 rows affected (4.33 sec)
Records: 443308  Duplicates: 0  Warnings: 0

##---------------------------------------------------------------
#2. Pesquisar os 15 primeiros registros da tabela cp_titles_date
##---------------------------------------------------------------

mysql> select * from cp_titles_date limit 15;
+--------------------+------------+
| title              | to_date    |
+--------------------+------------+
| Senior Engineer    | 9999-01-01 |
| Staff              | 9999-01-01 |
| Senior Engineer    | 9999-01-01 |
| Engineer           | 1995-12-01 |
| Senior Engineer    | 9999-01-01 |
| Senior Staff       | 9999-01-01 |
| Staff              | 1996-09-12 |
| Senior Engineer    | 9999-01-01 |
| Senior Staff       | 9999-01-01 |
| Staff              | 1996-02-11 |
| Assistant Engineer | 2000-07-31 |
| Assistant Engineer | 1990-02-18 |
| Engineer           | 1995-02-18 |
| Senior Engineer    | 9999-01-01 |
| Engineer           | 9999-01-01 |
+--------------------+------------+
15 rows in set (0.00 sec)


##---------------------------------------------------------------
#3. Alterar os registros do campo to_date para null da tabela cp_titles_date, quando o título for igual a Staff
##---------------------------------------------------------------
Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test_<numero_questao> e visualizar no HDFS

mysql> update cp_titles_date set to_date = NULL WHERE TITLE='Staff';
Query OK, 107391 rows affected (1.58 sec)
Rows matched: 107391  Changed: 107391  Warnings: 0

##---------------------------------------------------------------
#4. Importar a tabela titles com 8 mapeadores no formato parquet
##---------------------------------------------------------------

aline@aline-virtualbox:~/treinamentos/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# 

sqoop import --table titles \
--connect jdbc:mysql://database/employees \
--username root \
--password secret \
--num-mappers 8 \
--as-parquetfile \
--warehouse-dir /user/hive/warehouse/db_test_4 


root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test_4 
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-06 17:05 /user/hive/warehouse/db_test_4/titles


##---------------------------------------------------------------
#5. Importar a tabela titles com 8 mapeadores no formato parquet e compressão snappy
##---------------------------------------------------------------

sqoop import --table titles \
--connect jdbc:mysql://database/employees \
--username root \
--password secret \
--num-mappers 8 \
--as-parquetfile \
--warehouse-dir /user/hive/warehouse/db_test_5 \
--compression-codec org.apache.hadoop.io.compress.SnappyCodec

root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test_5 
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-06 17:10 /user/hive/warehouse/db_test_5/titles


##---------------------------------------------------------------
#6. Importar a tabela cp_titles_date com 4 mapeadores (erro)
##---------------------------------------------------------------

sqoop import --table cp_titles_date \
--connect jdbc:mysql://database/employees \
--username root \
--password secret \
--num-mappers 4 \
--warehouse-dir /user/hive/warehouse/db_test_6 \

21/09/06 17:14:32 ERROR tool.ImportTool: Import failed: No primary key could be found for table cp_titles_date. Please specify one with --split-by or perform a sequential import with '-m 1'.


#Importar a tabela cp_titles_date com 4 mapeadores divididos pelo campo título no warehouse /user/hive/warehouse/db_test2_title

sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --table cp_titles_date \
--connect jdbc:mysql://database/employees \
--username root \
--password secret \
--num-mappers 4 \
--split-by title \
--warehouse-dir /user/hive/warehouse/db_test2_title \

#Importar a tabela cp_titles_date com 4 mapeadores divididos pelo campo data no warehouse /user/hive/warehouse/db_test2_date

sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --table cp_titles_date \
--connect jdbc:mysql://database/employees \
--username root \
--password secret \
--num-mappers 4 \
--split-by to_date \
--warehouse-dir /user/hive/warehouse/db_test2_date \

#Qual a diferença dos registros nulos entre as duas importações?

root@namenode:/# hdfs dfs -count -h /user/hive/warehouse/db_test2_date

           2            5              7.7 M /user/hive/warehouse/db_test2_date


root@namenode:/# hdfs dfs -count -h /user/hive/warehouse/db_test2_title
           2            7              8.8 M /user/hive/warehouse/db_test2_title
		   
